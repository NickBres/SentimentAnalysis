{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:50.916868Z",
     "start_time": "2024-02-27T16:00:50.914751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "\n",
    "import tensorflow as tf # Deep Learning\n",
    "import tensorflow_hub as hub # Pre-trained models\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19fba2e84bdc0149"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('Twitter_Data.csv') # Read the data only with the columns that we need\n",
    "df.head() # Show the first 5 rows of the data\n",
    "df2 = pd.read_csv('Reddit_Data.csv')\n",
    "df2 = df2.rename(columns={'clean_comment': 'clean_text'})\n",
    "df = pd.concat([df, df2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.264103Z",
     "start_time": "2024-02-27T16:00:50.943665Z"
    }
   },
   "id": "1bc43258190cba17",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200229 entries, 0 to 37248\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  200125 non-null  object \n",
      " 1   category    200222 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.275468Z",
     "start_time": "2024-02-27T16:00:51.265043Z"
    }
   },
   "id": "54c27ed8f3a81fe4",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, there are missing values in the data. We will drop the missing values. Because it is a small amount of data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9086cbc0575972f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) # Drop the missing values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.291884Z",
     "start_time": "2024-02-27T16:00:51.276088Z"
    }
   },
   "id": "3de7fd234f660ea",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200118 entries, 0 to 37248\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  200118 non-null  object \n",
      " 1   category    200118 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.303297Z",
     "start_time": "2024-02-27T16:00:51.293269Z"
    }
   },
   "id": "c88a65ebca160918",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.,  0.,  1.])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.307565Z",
     "start_time": "2024-02-27T16:00:51.304014Z"
    }
   },
   "id": "1272c98c45bba332",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now need to convert the labels to numerical values. We will convert the labels to 0, 1, 2. 0 for Negative, 1 for Neutral, 2 for Positive."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "344ea1cf948d1754"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['category'] = df['category'].apply(lambda x: 0 if x == -1 else (1 if x == 0 else 2)) # Convert the labels to numerical values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.347162Z",
     "start_time": "2024-02-27T16:00:51.308125Z"
    }
   },
   "id": "73dbb793a98e6d45",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          clean_text  category\n0  when modi promised “minimum government maximum...         0\n1  talk all the nonsense and continue all the dra...         1\n2  what did just say vote for modi  welcome bjp t...         2\n3  asking his supporters prefix chowkidar their n...         2\n4  answer who among these the most powerful world...         2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>when modi promised “minimum government maximum...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>talk all the nonsense and continue all the dra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what did just say vote for modi  welcome bjp t...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>asking his supporters prefix chowkidar their n...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>answer who among these the most powerful world...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.351965Z",
     "start_time": "2024-02-27T16:00:51.347972Z"
    }
   },
   "id": "8cd8e22d49bba81f",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if data is balanced"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0cf2bd8845ace0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(43786, 68253, 88079)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['category'] == 0]) , len(df[df['category'] == 1]) , len(df[df['category'] == 2]) # Count the number of each label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.363535Z",
     "start_time": "2024-02-27T16:00:51.352590Z"
    }
   },
   "id": "dc3de6198c365f1",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data is balanced. Now we can convert the data to a tensorflow dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d2b136bea3418b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function that converts a panda dataframe to a tensorflow dataset\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=1024): # Function to convert a dataframe to a dataset\n",
    "    df = dataframe.copy() # avoid modifying the original dataframe\n",
    "    labels = df.pop(\"category\") # Remove the label column from the dataframe\n",
    "    df = df[\"clean_text\"] # Keep only the description column\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df, labels)) # Create a tensorflow dataset\n",
    "    if shuffle: # Shuffle the dataset if needed\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)  # Batch the dataset\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE) # automatically tune the number of batches to prefetch based on the current runtime conditions\n",
    "    return ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.366519Z",
     "start_time": "2024-02-27T16:00:51.364181Z"
    }
   },
   "id": "5d418508e6ebdfcc",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, val , test = np.split(df.sample(frac=1), [int(.8*len(df)), int(.9*len(df))]) # Split the data into train, validation and test sets with 80%, 10% and 10% of the data "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.389683Z",
     "start_time": "2024-02-27T16:00:51.368354Z"
    }
   },
   "id": "e9d7a7b7eac69a0e",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = df_to_dataset(train) # Convert the train dataframe to a tensorflow dataset\n",
    "val_data = df_to_dataset(val) # Convert the validation dataframe to a tensorflow dataset\n",
    "test_data = df_to_dataset(test) # Convert the test dataframe to a tensorflow dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.447983Z",
     "start_time": "2024-02-27T16:00:51.390422Z"
    }
   },
   "id": "2c2e12fe56e1c5c4",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e46900b05c03604a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to load a model of incompatible/unknown type. '/var/folders/71/vnznjlz52qj_1p44k0hb7sw00000gn/T/tfhub_modules/74a841d6eb84e8d93d913d716fb5440d020cc291' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://tfhub.dev/google/nnlm-en-dim50/2\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# Load the embedding model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m hub_layer \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKerasLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Create a keras layer with the embedding model\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/keras_layer.py:165\u001B[0m, in \u001B[0;36mKerasLayer.__init__\u001B[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_shape \u001B[38;5;241m=\u001B[39m data_structures\u001B[38;5;241m.\u001B[39mNoDependency(\n\u001B[1;32m    162\u001B[0m       _convert_nest_to_shapes(output_shape))\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func \u001B[38;5;241m=\u001B[39m \u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_is_hub_module_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/keras_layer.py:467\u001B[0m, in \u001B[0;36mload_module\u001B[0;34m(handle, tags, load_options)\u001B[0m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:  \u001B[38;5;66;03m# Expected before TF2.4.\u001B[39;00m\n\u001B[1;32m    466\u001B[0m       set_load_options \u001B[38;5;241m=\u001B[39m load_options\n\u001B[0;32m--> 467\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodule_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_load_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_hub/module_v2.py:113\u001B[0m, in \u001B[0;36mload\u001B[0;34m(handle, tags, options)\u001B[0m\n\u001B[1;32m    108\u001B[0m saved_model_pbtxt_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    109\u001B[0m     tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mas_bytes(module_path),\n\u001B[1;32m    110\u001B[0m     tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mas_bytes(tf\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(saved_model_path) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(saved_model_pbtxt_path)):\n\u001B[0;32m--> 113\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to load a model of incompatible/unknown type. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    114\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m contains neither \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m nor \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m    115\u001B[0m                    (module_path, tf\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PB,\n\u001B[1;32m    116\u001B[0m                     tf\u001B[38;5;241m.\u001B[39msaved_model\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m options:\n\u001B[1;32m    119\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(tf, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoadOptions\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "\u001B[0;31mValueError\u001B[0m: Trying to load a model of incompatible/unknown type. '/var/folders/71/vnznjlz52qj_1p44k0hb7sw00000gn/T/tfhub_modules/74a841d6eb84e8d93d913d716fb5440d020cc291' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'."
     ]
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\" # Load the embedding model\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True) # Create a keras layer with the embedding model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:00:51.471021Z",
     "start_time": "2024-02-27T16:00:51.448644Z"
    }
   },
   "id": "ee67bb5238f425c1",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential() # Create a sequential model\n",
    "model.add(hub_layer) # Add the pre-trained layer\n",
    "\n",
    "# Assuming the output of hub_layer is a flat vector. This is just a conceptual example.\n",
    "# In practice, CNNs need sequence or matrix inputs.\n",
    "#model.add(tf.keras.layers.Reshape((50, 1)))  # Reshape for CNN, if necessary\n",
    "#model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))  # Example CNN layer\n",
    "#model.add(tf.keras.layers.GlobalMaxPooling1D())  # Pooling layer to reduce dimensionality\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01))) # Add a hidden layer with 16 neurons\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax')) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe979fc5958fcae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001), # gradient descent algorithm\n",
    "    loss =  tf.keras.losses.SparseCategoricalCrossentropy(), # loss function\n",
    "    metrics = ['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36c98187bf97f91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.evaluate(train_data) # Evaluate the model on the test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "988f01f59275d414",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.evaluate(val_data) # Evaluate the model on the validation data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abff764f082bdb9d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data = val_data,\n",
    "    epochs = 10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a766f959d0724",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy') # Plot the accuracy of the model on the train data\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy') # Plot the accuracy of the model on the validation data\n",
    "plt.title('Accuracy of the model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a7cf29d3e661142",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss') # Plot the accuracy of the model on the train data\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss') # Plot the accuracy of the model on the validation data\n",
    "plt.title('Loss of the model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0839c50e0809584",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.evaluate(test_data) # Evaluate the model on the test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66f5ecf96b60c83",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict_sentiment(model, text):\n",
    "    \n",
    "    text = text.lower() # Convert the text to lowercase\n",
    "    # Convert the text to a pandas DataFrame\n",
    "    df = pd.DataFrame([text], columns=['Tweet'])\n",
    "\n",
    "    # Convert the DataFrame to a tensorflow dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices(df[\"Tweet\"]).batch(1)\n",
    "\n",
    "    # Use the model to predict the sentiment\n",
    "    prediction = model.predict(ds)\n",
    "\n",
    "    # Get the index of the maximum value (this will be the predicted label)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "    # Map the numerical label back to the original label\n",
    "    sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "    predicted_sentiment = sentiment_map[predicted_label]\n",
    "\n",
    "    # Print the predicted sentiment\n",
    "    print(f\"{text} is {predicted_sentiment}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ff4daeb689dbb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"I am Gilad Fisher\") \n",
    "predict_sentiment(model, \"I am Barak Finkel\")\n",
    "predict_sentiment(model, \"I am Nikita Breslavsky\")\n",
    "predict_sentiment(model, \"I hate Nikita Breslavsky\")\n",
    "predict_sentiment(model, \"I love Nikita Breslavsky\")\n",
    "predict_sentiment(model, \"I love to kill people\")\n",
    "predict_sentiment(model, \"I dont love myself\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e4a673c4f3c2bba",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
